{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Churn_Random Forest Classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "isMSAK8CINMN",
        "iudqAVbbGuJA",
        "wb8GA59tImEM"
      ],
      "authorship_tag": "ABX9TyOdsp+72RXigGEdyNiXDfPb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DLPY/Classification_Session_1/blob/main/Churn_Random_Forest_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset used**\n",
        "\n",
        "Churn Modelling: https://www.kaggle.com/shrutimechlearn/churn-modelling"
      ],
      "metadata": {
        "id": "_3j2sqrw-3VN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Import the relelvant packages and read the dataset"
      ],
      "metadata": {
        "id": "isMSAK8CINMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries \n",
        "\n",
        "import pandas as pd # Import Pandas for data manipulation using dataframes\n",
        "import numpy as np # Import Numpy for data statistical analysis \n",
        "import matplotlib.pyplot as plt # Import matplotlib for data visualisation\n",
        "%matplotlib inline\n",
        "import seaborn as sns # Statistical data visualization\n",
        "\n",
        "#Scikit-Learn otherwise known as sklearn is used for machine learning and has functionality for many types of classification models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, auc, classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "                             plot_roc_curve, PrecisionRecallDisplay, roc_auc_score, roc_curve)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.tree import export_graphviz # Visualize Tree\n",
        "from collections import OrderedDict\n",
        "from collections import Counter #Python Counter is a container that will hold the count of each of the elements present in the container\n",
        "from imblearn.under_sampling import RandomUnderSampler # provides tools when dealing with classification with imbalanced classes\n",
        "\n",
        "from pprint import pprint\n"
      ],
      "metadata": {
        "id": "DotyDhPW_bQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the data\n",
        "# CSV is first read in from a github raw file another option is to import the notebook to your session storage by click on the file icon on left toolbar then importing csv\n",
        "! wget https://raw.githubusercontent.com/DLPY/Classification_Session_1/master/Churn_Modelling.csv"
      ],
      "metadata": {
        "id": "YyVRspUQAR4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#reading the input file\n",
        "df_data = pd.read_csv('Churn_Modelling.csv')\n",
        "df_data.head()"
      ],
      "metadata": {
        "id": "zB0b6QinC60T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Churn Modeling Data Description**\n",
        "\n",
        "This data set contains details of a bank's customers and the target variable is a binary variable reflecting the fact whether the customer left the bank (closed their account) or they continue to be a customer.\n",
        "\n",
        "Here we have 13 feature columns and Exited is a target column.\n",
        "\n",
        "Row Numbers: Row Numbers from 1 to 10000.\n",
        "\n",
        "CustomerId: Unique Ids for bank customer identification.\n",
        "\n",
        "Surname: Customer's last name.\n",
        "\n",
        "CreditScore: Credit score of the customer.\n",
        "\n",
        "Geography: The country from which the customer belongs(Germany/France/Spain).\n",
        "\n",
        "Gender: Male or Female.\n",
        "\n",
        "Age: Age of the customer.\n",
        "\n",
        "Tenure: Number of years for which the customer has been with the bank.\n",
        "\n",
        "Balance: Bank balance of the customer.\n",
        "\n",
        "NumOfProducts: Number of bank products the customer is utilising.\n",
        "\n",
        "HasCrCard: Binary Flag for whether the customer holds a credit card with the bank or not(0=No, 1=Yes).\n",
        "\n",
        "IsActiveMember: Binary Flag for whether the customer is an active member with the bank or not(0=No, 1=Yes).\n",
        "\n",
        "EstimatedSalary: Estimated salary of the customer in Euro.\n",
        "\n",
        "Exited: Binary flag 1 if the customer closed account with bank and 0 if the customer is retained(0=No, 1=Yes)."
      ],
      "metadata": {
        "id": "pupM_d7mIcmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Data Transformation"
      ],
      "metadata": {
        "id": "iudqAVbbGuJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Removing columns that do not add value to the analysis\n",
        "df_data = df_data.drop(['RowNumber', 'CustomerId','Surname'],axis=1)\n",
        "df_data.head()"
      ],
      "metadata": {
        "id": "EtT04QOfEjmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encoding the categorical variables - Change the text into numbers**"
      ],
      "metadata": {
        "id": "sjy62XwKFYmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert the categorical values into numeric categorical labels so that this data can be used for modelling.\n",
        "df_data['CountryCode'] = df_data['Geography'].astype('category').cat.codes\n",
        "df_data['GenderCode'] = df_data['Gender'].astype('category').cat.codes"
      ],
      "metadata": {
        "id": "x2oilPDJFdlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_data.head(5)"
      ],
      "metadata": {
        "id": "tnl40HWCFt4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above, notice that:\n",
        "\n",
        "The Geography and Gender have been converted to numeric values.\n",
        "\n",
        "There are two new columns with these values: CountryCode and GenderCode."
      ],
      "metadata": {
        "id": "NECx1S4PF15r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#droping the string columns as we have the respective numeric columns\n",
        "df_data = df_data.drop(['Geography', 'Gender'],axis=1)"
      ],
      "metadata": {
        "id": "rdeVj8ixHA2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Choosing predictor variables and target variable for performing Classification\n",
        "Target and Source variables** \n",
        "\n",
        "\n",
        "Target Variable: Exited\n",
        "\n",
        "Predictor Variables: CreditScore, CountryCode, GenderCode, Age, Tenure, Balance, NumOfProducts, HasCrCard, IsActiveMember, EstimatedSalary"
      ],
      "metadata": {
        "id": "XGS6Mr_MHRgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_data.drop(['Exited'],axis=1) #selecting all variables except \"exited\" as our predictor variables\n",
        "\n",
        "y = df_data['Exited'] # selecting \"Exited\" column as our target variable\n",
        "\n",
        "# Save this list of column values for later\n",
        "columns_list = list(X.columns.values)"
      ],
      "metadata": {
        "id": "_WUgi5d4HJUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.head(5)"
      ],
      "metadata": {
        "id": "UUa1wbpCH4Vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.head(5)"
      ],
      "metadata": {
        "id": "Vjp-KRKxH4f1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split dataset into the training and test"
      ],
      "metadata": {
        "id": "wb8GA59tImEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)\n",
        "\n",
        "print('Training Data:', X_train.shape, y_train.shape)\n",
        "print('Testing Data:', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "900HFhxRIrlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train, Test and Predict using a Random Forest Classifier model"
      ],
      "metadata": {
        "id": "yv5CXzJmI3b-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 1 : Basic**"
      ],
      "metadata": {
        "id": "D-UZmufDPANc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object using RandomForestClassifier with default parameters\n",
        "randomforest_classifier_m1 = RandomForestClassifier()\n",
        "# Fit the classification model to the training set data.\n",
        "randomforest_classifier_m1.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "p4GIsLv6JIy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how the model predicts training data\n",
        "y_predict_train = randomforest_classifier_m1.predict(X_train)\n",
        "#creating confusion matrix\n",
        "cm = confusion_matrix(y_train, y_predict_train)"
      ],
      "metadata": {
        "id": "62wbAECMKpkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_predict_train, cmap='RdPu_r')\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "2_PEGHLFK4QC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for training data \n",
        "print(classification_report(y_train, y_predict_train))"
      ],
      "metadata": {
        "id": "DU17bDFmK64L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how the model predicts testing data\n",
        "y_predict_m1 = randomforest_classifier_m1.predict(X_test)\n",
        "#creating confusion matrix\n",
        "cm_m1 = confusion_matrix(y_test, y_predict_m1)"
      ],
      "metadata": {
        "id": "7ATKCvPmL9QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_predict_m1, cmap='RdPu_r')\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "oJa38kkOMOZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for testing data \n",
        "print(classification_report(y_test, y_predict_m1))"
      ],
      "metadata": {
        "id": "ML68h_7JMSo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Parameters currently in use:\\n')\n",
        "pprint(randomforest_classifier_m1.get_params())"
      ],
      "metadata": {
        "id": "248MdrzlJR-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract one of the trees from the model\n",
        "tree = randomforest_classifier_m1.estimators_[6]\n",
        "\n",
        "#defining features adn target variables\n",
        "target = list(df_data['Exited'].unique())\n",
        "feature_names = list(X.columns.values)\n",
        "\n",
        "# Export as dot file\n",
        "export_graphviz(tree, out_file='tree.dot',\n",
        "feature_names =feature_names, class_names=['Left', 'Stayed'], rounded = True, proportion = False, precision = 2, filled = True, max_depth=3)\n",
        "# Convert to png using system command (requires Graphviz)\n",
        "from subprocess import call\n",
        "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=90'])\n",
        "# Display in jupyter notebook\n",
        "from IPython.display import Image\n",
        "Image(filename = 'tree.png')"
      ],
      "metadata": {
        "id": "ACISRiHM4piN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract one of the trees from the model\n",
        "tree = randomforest_classifier_m1.estimators_[55]\n",
        "\n",
        "#defining features adn target variables\n",
        "target = list(df_data['Exited'].unique())\n",
        "feature_names = list(X.columns.values)\n",
        "\n",
        "# Export as dot file\n",
        "export_graphviz(tree, out_file='tree.dot',\n",
        "feature_names =feature_names, class_names=['Left', 'Stayed'], rounded = True, proportion = False, precision = 2, filled = True, max_depth=3)\n",
        "# Convert to png using system command (requires Graphviz)\n",
        "from subprocess import call\n",
        "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=90'])\n",
        "# Display in jupyter notebook\n",
        "from IPython.display import Image\n",
        "Image(filename = 'tree.png')"
      ],
      "metadata": {
        "id": "dq4KQFqr6rZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 2 : Using Undersampled Data**\n",
        "\n",
        "Resampling the dataset due to class imbalance"
      ],
      "metadata": {
        "id": "Kw5SzPMcQQyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize class distribution\n",
        "print(\"Before undersampling: \", Counter(y_train))\n",
        "\n",
        "# define undersampling strategy\n",
        "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
        "\n",
        "# fit and apply the transform\n",
        "X_train_under, y_train_under = undersample.fit_resample(X_train, y_train)\n",
        "\n",
        "# summarize class distribution\n",
        "print(\"After undersampling: \", Counter(y_train_under))"
      ],
      "metadata": {
        "id": "hvG0CnUHPjuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object using RandomForestClassifier with default parameters\n",
        "randomforest_classifier_m2 = RandomForestClassifier()\n",
        "# Fit the classification model to the training set data.\n",
        "randomforest_classifier_m2.fit(X_train_under, y_train_under)"
      ],
      "metadata": {
        "id": "bMaNp4GHPs3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check how the model predicts testing data\n",
        "y_predict_m2 = randomforest_classifier_m2.predict(X_test)\n",
        "#creating confusion matrix\n",
        "cm_m2 = confusion_matrix(y_test, y_predict_m2)"
      ],
      "metadata": {
        "id": "qh1O3YmKP0gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_predict_m2, cmap='RdPu_r')\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "XR6S_RmXQDAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for testing data \n",
        "print(classification_report(y_test, y_predict_m2))"
      ],
      "metadata": {
        "id": "YYylYTZPQJWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NOTE: Setting the `warm_start` construction parameter to `True` disables\n",
        "# support for parallelized ensembles but is necessary for tracking the OOB\n",
        "# error trajectory during training.\n",
        "ensemble_clfs = [\n",
        "    (\n",
        "        \"RandomForestClassifier, max_features='sqrt'\",\n",
        "        RandomForestClassifier(\n",
        "            warm_start=True,\n",
        "            oob_score=True,\n",
        "            max_features=\"sqrt\",\n",
        "            random_state=5,\n",
        "        ),\n",
        "    ),\n",
        "    (\n",
        "        \"RandomForestClassifier, max_features='log2'\",\n",
        "        RandomForestClassifier(\n",
        "            warm_start=True,\n",
        "            max_features=\"log2\",\n",
        "            oob_score=True,\n",
        "            random_state=5,\n",
        "        ),\n",
        "    ),\n",
        "    (\n",
        "        \"RandomForestClassifier, max_features=None\",\n",
        "        RandomForestClassifier(\n",
        "            warm_start=True,\n",
        "            max_features=None,\n",
        "            oob_score=True,\n",
        "            random_state=5,\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
        "error_rate = OrderedDict((label, []) for label, _ in ensemble_clfs)\n",
        "\n",
        "# Range of `n_estimators` values to explore.\n",
        "min_estimators = 50\n",
        "max_estimators = 700\n",
        "\n",
        "for label, clf in ensemble_clfs:\n",
        "    for i in range(min_estimators, max_estimators + 1, 50):\n",
        "        clf.set_params(n_estimators=i)\n",
        "        clf.fit(X, y)\n",
        "\n",
        "        # Record the OOB error for each `n_estimators=i` setting.\n",
        "        oob_error = 1 - clf.oob_score_\n",
        "        error_rate[label].append((i, oob_error))\n",
        "\n",
        "# Generate the \"OOB error rate\" vs. \"n_estimators\" plot.\n"
      ],
      "metadata": {
        "id": "PouwsJy29oIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label, clf_err in error_rate.items():\n",
        "    xs, ys = zip(*clf_err)\n",
        "    plt.plot(xs, ys, label=label)\n",
        "\n",
        "plt.xlim(min_estimators, max_estimators)\n",
        "plt.xlabel(\"n_estimators\")\n",
        "plt.ylabel(\"OOB error rate\")\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4CPP6xAEe-VH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(error_rate)"
      ],
      "metadata": {
        "id": "stZTtSVDqoXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model 3 : Using Best parameters found**"
      ],
      "metadata": {
        "id": "q1eU4CyzQZ9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an object using DecisionTreeClassifier, setting a few parameters such as max depth.\n",
        "randomforest_classifier_m3 = RandomForestClassifier(n_estimators = 600, criterion = 'gini',min_samples_split =7,min_samples_leaf =7,\n",
        "                                                 max_features='log2',max_depth=None,bootstrap=True)\n",
        "randomforest_classifier_m3.fit(X_train_under, y_train_under)\n",
        "y_predict_m3 = randomforest_classifier_m3.predict(X_test)\n",
        "cm_m3 = confusion_matrix(y_test, y_predict_m3)"
      ],
      "metadata": {
        "id": "ChHEdFMOQew5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plot confusion matrix\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_predict_m3, cmap='RdPu_r')\n",
        "plt.grid(False)"
      ],
      "metadata": {
        "id": "IkLuq2GNRlJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for testing data \n",
        "print(classification_report(y_test, y_predict_m3))"
      ],
      "metadata": {
        "id": "UO620T_PRo0F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_importances = pd.Series(randomforest_classifier_m3.feature_importances_, index=X.columns)\n",
        "feat_importances.nlargest(10).sort_values().plot(kind='barh', title='Feature Importance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hevuplqpR-q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model comparison\n",
        "print('Model 1 : Basic')\n",
        "print(classification_report(y_test, y_predict_m1))\n",
        "print('-----------------------------------------------------------------')\n",
        "print('Model 2 : Using Undersampled Data')\n",
        "print(classification_report(y_test, y_predict_m2))\n",
        "print('-----------------------------------------------------------------')\n",
        "print('Model 3 : Using Best parameters found ')\n",
        "print(classification_report(y_test, y_predict_m3))\n",
        "print('-----------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "sL5i-Lh1q0Tk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Conclusion**\n",
        "\n",
        "1. Model 1 has the highest accuracy compared to the other two models but that is misleading.\n",
        "\n",
        "2. We notice that model 1 has a very low recall and high precision for Prediction of class 1 but that flips in the subsequent models.\n",
        "\n",
        "3. The f1-score is the best for our last model which gives us some confidence that the steps applied have improved the performance of the model\n",
        "\n",
        "4. The support for Class 1 prediction is low (624) compared to Class 0 prediction (2376) which again shows the data still an imbalance issue and hence other sampling techniques can be applied to achieve better models.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MlgrmZAWE6D0"
      }
    }
  ]
}